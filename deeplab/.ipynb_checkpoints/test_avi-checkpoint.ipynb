{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###  COPY ALL THE CODE INTO A JYPYTER NOTEBOOK  ### \n",
    "###  THE JYPYTER NOTEBOOK NEEDS TO BE IN 'tensorflow\\models\\research\\deeplab'  ### \n",
    "\n",
    "## Imports\n",
    "\n",
    "import collections\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import tarfile\n",
    "import tempfile\n",
    "import urllib\n",
    "\n",
    "from IPython import display\n",
    "from ipywidgets import interact\n",
    "from ipywidgets import interactive\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# import skvideo.io\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "if tf.__version__ < '1.5.0':\n",
    "    raise ImportError('Please upgrade your tensorflow installation to v1.5.0 or newer!')\n",
    "\n",
    "# Needed to show segmentation colormap labels\n",
    "sys.path.append('utils')\n",
    "import get_dataset_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Select and download models\n",
    "\n",
    "_MODEL_URLS = {\n",
    "    'xception_coco_voctrainaug': 'http://download.tensorflow.org/models/deeplabv3_pascal_train_aug_2018_01_04.tar.gz',\n",
    "    'xception_coco_voctrainval': 'http://download.tensorflow.org/models/deeplabv3_pascal_trainval_2018_01_04.tar.gz',\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Config = collections.namedtuple('Config', 'model_url, model_dir')\n",
    "\n",
    "def get_config(model_name, model_dir):\n",
    "    return Config(_MODEL_URLS[model_name], model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_widget = interactive(get_config, model_name='xception_coco_voctrainval', model_dir='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(model_url='http://download.tensorflow.org/models/deeplabv3_pascal_trainval_2018_01_04.tar.gz', model_dir='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.display(config_widget)\n",
    "\n",
    "# Check configuration and download the model\n",
    "\n",
    "_TARBALL_NAME = 'deeplab_model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading model to /tmp/tmpqcbpl44l/deeplab_model.tar.gz, this might take a while...\n",
      "download completed!\n"
     ]
    }
   ],
   "source": [
    "config = config_widget.result\n",
    "\n",
    "model_dir = config.model_dir or tempfile.mkdtemp()\n",
    "tf.gfile.MakeDirs(model_dir)\n",
    "\n",
    "download_path = os.path.join(model_dir, _TARBALL_NAME)\n",
    "print('downloading model to %s, this might take a while...' % download_path)\n",
    "urllib.request.urlretrieve(config.model_url, download_path)\n",
    "print('download completed!')\n",
    "\n",
    "\n",
    "## Load model in TensorFlow\n",
    "\n",
    "_FROZEN_GRAPH_NAME = 'frozen_inference_graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DeepLabModel(object):\n",
    "    \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
    "    \n",
    "    INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "    INPUT_SIZE = 513\n",
    "\n",
    "    def __init__(self, tarball_path):\n",
    "        \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        graph_def = None\n",
    "        # Extract frozen graph from tar archive.\n",
    "        tar_file = tarfile.open(tarball_path)\n",
    "        for tar_info in tar_file.getmembers():\n",
    "            if _FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
    "                file_handle = tar_file.extractfile(tar_info)\n",
    "                graph_def = tf.GraphDef.FromString(file_handle.read())\n",
    "                break\n",
    "\n",
    "        tar_file.close()\n",
    "        \n",
    "        if graph_def is None:\n",
    "            raise RuntimeError('Cannot find inference graph in tar archive.')\n",
    "\n",
    "        with self.graph.as_default():      \n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "        \n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "            \n",
    "    def run(self, image):\n",
    "        \"\"\"Runs inference on a single image.\n",
    "        \n",
    "        Args:\n",
    "            image: A PIL.Image object, raw input image.\n",
    "            \n",
    "        Returns:\n",
    "            resized_image: RGB image resized from original input image.\n",
    "            seg_map: Segmentation map of `resized_image`.\n",
    "        \"\"\"\n",
    "        width, height = image.size\n",
    "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "        resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "        batch_seg_map = self.sess.run(\n",
    "            self.OUTPUT_TENSOR_NAME,\n",
    "            feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
    "        seg_map = batch_seg_map[0]\n",
    "        return resized_image, seg_map\n",
    "\n",
    "model = DeepLabModel(download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Webcam demo\n",
    "cap = cv2.VideoCapture(\"/workspace/tensorflow/avi/hotel.mp4\")\n",
    "\n",
    "# Next line may need adjusting depending on webcam resolution\n",
    "final = np.zeros((1, 384, 1026, 3))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Webcam demo\n",
    "cap = cv2.VideoCapture(\"/workspace/tensorflow/avi/hotel.mp4\")\n",
    "\n",
    "# Next line may need adjusting depending on webcam resolution\n",
    "final = np.zeros((1, 384, 1026, 3))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # From cv2 to PIL\n",
    "    cv2_im = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_im = Image.fromarray(cv2_im)\n",
    "    \n",
    "    # Run model\n",
    "    resized_im, seg_map = model.run(pil_im)\n",
    "    \n",
    "    # Adjust color of mask\n",
    "    seg_image = get_dataset_colormap.label_to_color_image(\n",
    "        seg_map, get_dataset_colormap.get_pascal_name()).astype(np.uint8)\n",
    "    \n",
    "    # Convert PIL image back to cv2 and resize\n",
    "    frame = np.array(pil_im)\n",
    "    r = seg_image.shape[1] / frame.shape[1]\n",
    "    dim = (int(frame.shape[0] * r), seg_image.shape[1])[::-1]\n",
    "    resized = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "    resized = cv2.cvtColor(resized, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Stack horizontally color frame and mask\n",
    "    color_and_mask = np.hstack((resized, seg_image))\n",
    "\n",
    "    cv2.imshow('frame', color_and_mask)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "    \n",
    "###  UNCOMMENT NEXT LINES TO SAVE THE VIDEO  ###\n",
    "output = np.expand_dims(both, axis=0)\n",
    "final = np.append(final, output, 0)\n",
    "skvideo.io.vwrite(\"outputvideo111.mp4\", final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "37331f47918443dea9a76cfcfa817817": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
